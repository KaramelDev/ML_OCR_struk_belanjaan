{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf681e5a",
   "metadata": {},
   "source": [
    "ini jadi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "155a178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import re\n",
    "from sentence_transformers import util\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from fastapi import FastAPI, UploadFile, File\n",
    "from fastapi.responses import JSONResponse\n",
    "import tempfile\n",
    "import nest_asyncio\n",
    "import uvicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e07f98",
   "metadata": {},
   "source": [
    "ambil data pusat dari postgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51356816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_pusat():\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"strukAI\",\n",
    "        user=\"postgres\",\n",
    "        password=\"bairn1021\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    df = pd.read_sql_query(\"SELECT * FROM data_pusat\", conn)\n",
    "    conn.close()\n",
    "\n",
    "    df = df.dropna()\n",
    "    descriptions = df[\"Description\"].astype(str).str.lower().tolist()\n",
    "    ids = df[\"id\"].tolist()\n",
    "    prices = df[\"Harga Jual ke Konsumen yg Disarankan\"].tolist()\n",
    "\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    vectors = model.encode(descriptions, convert_to_tensor=True)\n",
    "\n",
    "    return df, descriptions, ids, prices, model, vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c57f3",
   "metadata": {},
   "source": [
    "OCR menggunakan Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660edbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"AIzaSyCG8IGd5lgD4m2UocqUGOyGtyd0jM6O4vU\")\n",
    "model_gemini = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "def OCR_Gemini(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    prompt = \"\"\"\n",
    "    Ini adalah struk belanja. Tolong ekstrak informasinya dalam format JSON dengan field:\n",
    "    - invoice_number (string)\n",
    "    - phone (string)\n",
    "    - alamat (string)\n",
    "    - email (string)\n",
    "    - nama_toko (string)\n",
    "    - tanggal (string, format DD/MM/YYYY)\n",
    "    - daftar_barang (array of objects: nama, qty, harga_satuan, subtotal)\n",
    "    - total_belanja (number)\n",
    "    Jika ada informasi yang tidak jelas, isi dengan null.\n",
    "    Hanya kembalikan JSON-nya saja, tanpa penjelasan atau markdown formatting.lowercase\n",
    "    \"\"\"\n",
    "    response = model_gemini.generate_content([prompt, img])\n",
    "    text = response.text\n",
    "    cleaned = re.sub(r'^```json|```$', '', text, flags=re.MULTILINE).strip()\n",
    "    return json.loads(cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370635ac",
   "metadata": {},
   "source": [
    "Fungsi untuk menentukan kesamaan data hasil OCR dengan data yang ada di pusat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "778a68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_items(items, descriptions, ids, vectors, model, threshold=0.59):\n",
    "    result = []\n",
    "\n",
    "    for i, item in enumerate(items):\n",
    "        vektor_item = model.encode(item['nama'], convert_to_tensor=True)\n",
    "        similarity = util.cos_sim(vektor_item, vectors)\n",
    "        idx_best = similarity.argmax()\n",
    "        skor = similarity[0][idx_best].item()\n",
    "\n",
    "        if skor >= threshold:\n",
    "            result.append({\n",
    "                \"id\": int(ids[idx_best]),\n",
    "                \"name\": descriptions[idx_best],\n",
    "                \"ocr_result\": {\n",
    "                    \"name\": item['nama'],\n",
    "                    \"quantity\": float(item['qty']),\n",
    "                    \"price\": float(item['harga_satuan']),\n",
    "                    \"total\": float(item['subtotal']),\n",
    "                    \"accuration\": round(skor, 4)\n",
    "                }\n",
    "            })\n",
    "        else:\n",
    "            result.append({\n",
    "                \"id\": None,\n",
    "                \"name\": None,\n",
    "                \"ocr_result\": {\n",
    "                    \"name\": item['nama'],\n",
    "                    \"quantity\": float(item['qty']),\n",
    "                    \"price\": float(item['harga_satuan']),\n",
    "                    \"total\": float(item['subtotal']),\n",
    "                    \"accuration\": round(skor, 4)\n",
    "                }\n",
    "            })\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e5b3c",
   "metadata": {},
   "source": [
    "Menentukan type Outout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777e9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRResult(BaseModel):\n",
    "    name: str\n",
    "    quantity: float\n",
    "    price: float\n",
    "    total: float\n",
    "    accuration: float\n",
    "\n",
    "class ItemMatched(BaseModel):\n",
    "    id: int| None\n",
    "    name:str | None\n",
    "    ocr_result: OCRResult\n",
    "\n",
    "class Merchant(BaseModel):\n",
    "    name: str | None\n",
    "    address:str | None\n",
    "    phone: str | None\n",
    "    email: str | None\n",
    "\n",
    "class FinalOutput(BaseModel):\n",
    "    invoice_number: str\n",
    "    tanggal: str\n",
    "    merchant: Merchant\n",
    "    items: List[ItemMatched]\n",
    "    grand_total: float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be033bd9",
   "metadata": {},
   "source": [
    "Set UP fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c025625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naeko\\AppData\\Local\\Temp\\ipykernel_16080\\1049571093.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(\"SELECT * FROM data_pusat\", conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77adddc931ee4bf9bf8a0a0de1a93bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pkl\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\naeko\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d4108b4e864e52864856187e6869ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cebfc52f7714a10bdccc8f0a0755de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0377b1884023456b86ae4d565b0ed6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0695ef2912114aceb517eacfeeb73432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b30d81668241279d14c694cca612d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea07174c62304c979653f78ee29a03c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1bf7cf2c904af384ac34065fa74cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c8a5175f374067baa408332f77ad47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ac890e42ab4dcd8ae6be540e6eb166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd41029aba3d4fb0a40def822f08edfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = FastAPI()\n",
    "df, descriptions, ids, prices, model, vectors = load_data_pusat()\n",
    "\n",
    "@app.post(\"/struk\", response_model=FinalOutput)\n",
    "async def struk(file: UploadFile = File(...)):\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".jpg\") as tmp:\n",
    "        tmp.write(await file.read())\n",
    "        path = tmp.name\n",
    "\n",
    "    try:\n",
    "        OCRData = OCR_Gemini(path)\n",
    "        items = OCRData['daftar_barang']\n",
    "        matched = match_items(items, descriptions, ids, vectors, model)\n",
    "\n",
    "        result = {\n",
    "            \"invoice_number\": OCRData['invoice_number'],\n",
    "            \"tanggal\": OCRData['tanggal'],\n",
    "            \"merchant\": {\n",
    "                \"name\": OCRData['nama_toko'],\n",
    "                \"address\": OCRData['alamat'],\n",
    "                \"phone\": OCRData['phone'],\n",
    "                \"email\": OCRData['email']\n",
    "            },\n",
    "            \"items\": matched,\n",
    "            \"grand_total\": float(OCRData['total_belanja'])\n",
    "        }\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return JSONResponse(status_code=500, content={\"error\": str(e)})\n",
    "\n",
    "@app.get(\"/\")\n",
    "def health_check():\n",
    "    return {\"status\": \"running\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a70f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [16080]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:52476 - \"POST /struk HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52484 - \"POST /struk HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52509 - \"POST /struk HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52518 - \"POST /struk HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [16080]\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bdd181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
